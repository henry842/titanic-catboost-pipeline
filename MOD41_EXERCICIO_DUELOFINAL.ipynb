{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X2EpQW3E84Ya"
   },
   "source": [
    "# **Exercicio Duelo de Modelos 4**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dqo2ronY9w4E"
   },
   "source": [
    "Nesta tarefa, voc√™s ir√£o criar o seu pr√≥prio duelo de modelos, com o objetivo de superar os resultados apresentados em aula. O desafio √© alcan√ßar um desempenho superior ao que obtivemos, e para isso, ser√° necess√°rio aplicar todas as melhorias que voc√™s aprenderam ao longo dos m√≥dulos, utilizando a base de dados do Titanic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZG3kKnOQ91xm"
   },
   "source": [
    "**1. Escolha do Modelo:**\n",
    "Selecione um dos modelos que foram explorados nos duelos de modelos ao longo do curso. Pode ser SVM, Random Forest, XGBoost, ou qualquer outro que tenhamos abordado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dVrtylnB97mf"
   },
   "source": [
    "**2. Aperfei√ßoamento:**\n",
    "**Aplique as t√©cnicas que aprendemos para melhorar o desempenho do seu modelo:**\n",
    "\n",
    "**Hiperpar√¢metros:** Utilize GridSearchCV ou RandomSearchCV para encontrar os melhores par√¢metros.\n",
    "\n",
    "**Cross Validation:** Avalie a robustez do modelo utilizando valida√ß√£o cruzada para garantir que ele generaliza bem.\n",
    "\n",
    "**Balanceamento de Classes:** Se o seu modelo lida com problemas de classes desbalanceadas, explore t√©cnicas como SMOTE, undersampling ou oversampling.\n",
    "\n",
    "**Padroniza√ß√£o e Normaliza√ß√£o:** Lembre-se de padronizar os dados, especialmente se for usar modelos que s√£o sens√≠veis √† escala das vari√°veis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5nrSntC-GtC"
   },
   "source": [
    "**3. Submiss√£o no Kaggle:**\n",
    "Treine o seu modelo com os dados de treino e gere as previs√µes para os dados de teste. Lembre-se de que o conjunto de teste n√£o possui a vari√°vel alvo (y_test), pois a avalia√ß√£o ser√° feita com base nas submiss√µes no Kaggle.\n",
    "Submeta suas previs√µes na competi√ß√£o do Titanic no Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I3k5a5jD-M2Q"
   },
   "source": [
    "**4. Entrega:**\n",
    "Envie o c√≥digo que voc√™ desenvolveu, detalhando cada etapa do seu processo de modelagem, explicando as escolhas feitas e como essas ajudaram a melhorar o modelo.\n",
    "\n",
    "Junto com o c√≥digo, envie um print do seu score obtido na plataforma do Kaggle. Esse score ser√° a sua m√©trica final de avalia√ß√£o, mostrando como o seu modelo se compara com os demais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MnLbij2e-QLX"
   },
   "source": [
    "**5. Competi√ß√£o Saud√°vel:**\n",
    "A ideia √© trazer um senso de competi√ß√£o saud√°vel, ent√£o n√£o vale replicar exatamente o que fizemos na aula! Inove, explore novas combina√ß√µes de par√¢metros e t√©cnicas, e mostre do que √© capaz. O importante √© exercitar o pensamento cr√≠tico e a capacidade de experimentar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K0LftJMB-Vlu"
   },
   "source": [
    "**Dicas Finais:**\n",
    "\n",
    "Seja criativo e tenha um olhar cr√≠tico sobre o que pode ser melhorado.\n",
    "Teste diferentes abordagens e n√£o se prenda a um √∫nico caminho.\n",
    "Lembre-se de que, mais do que alcan√ßar o melhor score, o objetivo √© aprender e aplicar o conhecimento de forma pr√°tica e eficaz.\n",
    "Boa sorte! Estamos ansiosos para ver como cada um de voc√™s vai se sair nesse desafio e quais insights ir√£o surgir dessa competi√ß√£o!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BE1hkFA6-XOM"
   },
   "source": [
    "Ao final dessa atividade voc√™s ter√£o participado da primeira competi√ß√£o publica de ci√™ncia de dados de voc√™s = )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'catboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StratifiedKFold\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcatboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CatBoostClassifier, Pool\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'catboost'"
     ]
    }
   ],
   "source": [
    "# ===================================================\n",
    "# 1Ô∏è‚É£ Imports e Configura√ß√µes Globais\n",
    "# ===================================================\n",
    "\n",
    "import os, re, warnings, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Tuple\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from catboost import CatBoostClassifier, Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1Ô∏è‚É£ Imports e Configura√ß√µes Globais\n",
    "\n",
    "O que tem dentro:\n",
    "\n",
    "os, re, warnings, random: utilit√°rios do Python para manipula√ß√£o de arquivos, express√µes regulares, warnings e gera√ß√£o de n√∫meros aleat√≥rios.\n",
    "\n",
    "numpy, pandas: bibliotecas essenciais para c√°lculo num√©rico e manipula√ß√£o de tabelas (DataFrames).\n",
    "\n",
    "sklearn.model_selection.StratifiedKFold: para criar folds estratificados na valida√ß√£o cruzada.\n",
    "\n",
    "sklearn.metrics.accuracy_score: para medir a acur√°cia do modelo.\n",
    "\n",
    "catboost.CatBoostClassifier, Pool: modelo principal e estrutura de dados espec√≠fica para CatBoost.\n",
    "\n",
    "Fun√ß√£o:\n",
    "\n",
    "Permite ler e manipular os dados (pandas), fazer c√°lculos e opera√ß√µes num√©ricas (numpy), criar valida√ß√£o cruzada estratificada (StratifiedKFold), medir performance (accuracy_score) e treinar o modelo (CatBoost).\n",
    "\n",
    "Por que escolhi:\n",
    "\n",
    "CatBoost √© √≥timo para dados mistos (num√©ricos + categ√≥ricos) e geralmente supera XGBoost/LightGBM sem precisar de muito encoding manual.\n",
    "\n",
    "StratifiedKFold evita que folds tenham distribui√ß√£o desigual de sobreviventes.\n",
    "\n",
    "warnings e np.set_printoptions garantem que o notebook seja mais limpo e leg√≠vel.\n",
    "\n",
    "Configura√ß√µes globais:\n",
    "\n",
    "RANDOM_STATE: para reprodutibilidade.\n",
    "\n",
    "N_SPLITS: n√∫mero de folds para CV.\n",
    "\n",
    "TE_SMOOTHING: suaviza√ß√£o para target encoding, evita overfitting.\n",
    "\n",
    "EARLY_STOPPING_ROUNDS: para parar o treinamento se n√£o houver melhora.\n",
    "\n",
    "PSEUDO_LABEL, PL_POS_THR, PL_NEG_THR: controlam pseudo-labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configura√ß√µes gerais\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "N_SPLITS = 5\n",
    "TE_SMOOTHING = 20.0\n",
    "EARLY_STOPPING_ROUNDS = 200\n",
    "PSEUDO_LABEL = True          # True para usar pseudo-labeling, False para n√£o usar\n",
    "PL_POS_THR, PL_NEG_THR = 0.98, 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================\n",
    "# 2Ô∏è‚É£ Fun√ß√µes utilit√°rias\n",
    "# ===================================================\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    \"\"\"Fixar seeds para reprodutibilidade\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    try:\n",
    "        import torch\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "def detect_input_dir():\n",
    "    \"\"\"Detecta a pasta onde os arquivos train/test CSV est√£o localizados\"\"\"\n",
    "    for p in [\"../input/titanic\", \"../input/Titanic\", \"./\"]:\n",
    "        if os.path.exists(os.path.join(p, \"train.csv\")):\n",
    "            return p\n",
    "    return \"./\"\n",
    "\n",
    "def extract_title(name: str) -> str:\n",
    "    \"\"\"Extrai t√≠tulo do nome do passageiro\"\"\"\n",
    "    if pd.isna(name): return \"Unknown\"\n",
    "    m = re.search(r\",\\s*([^\\.]+)\\.\", name)\n",
    "    return m.group(1).strip() if m else \"Unknown\"\n",
    "\n",
    "def clean_ticket_prefix(s: str) -> str:\n",
    "    \"\"\"Limpa e padroniza prefixo do ticket\"\"\"\n",
    "    if pd.isna(s): return \"NONE\"\n",
    "    s = str(s).upper()\n",
    "    s = re.sub(r\"[./]\", \"\", s)\n",
    "    s = re.sub(r\"\\s+\", \"\", s)\n",
    "    s = re.sub(r\"\\d+\", \"\", s)\n",
    "    return s if s else \"NONE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2Ô∏è‚É£ Fun√ß√µes utilit√°rias\n",
    "\n",
    "O que tem dentro:\n",
    "\n",
    "seed_everything(): fixa sementes de aleatoriedade no Python, numpy e PyTorch (se dispon√≠vel) para resultados reproduz√≠veis.\n",
    "\n",
    "detect_input_dir(): localiza automaticamente onde os arquivos train.csv e test.csv est√£o.\n",
    "\n",
    "extract_title(name): extrai o t√≠tulo do passageiro do campo Name.\n",
    "\n",
    "clean_ticket_prefix(s): limpa e padroniza prefixos de tickets (ex.: \"A/5 21171\" ‚Üí \"A\").\n",
    "\n",
    "Fun√ß√£o:\n",
    "\n",
    "Garantir consist√™ncia nos experimentos (seed_everything).\n",
    "\n",
    "Facilitar leitura de dados sem precisar alterar paths (detect_input_dir).\n",
    "\n",
    "Criar features relevantes a partir de campos textuais (extract_title e clean_ticket_prefix).\n",
    "\n",
    "Por que escolhi:\n",
    "\n",
    "A an√°lise do Titanic mostra que t√≠tulos (Mr, Mrs, Master) e prefixos de tickets podem refletir status social ou grupos de viagem, impactando sobreviv√™ncia.\n",
    "\n",
    "Limpeza de strings evita categorias inconsistentes e reduz cardinalidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================\n",
    "# 3Ô∏è‚É£ Fun√ß√£o de Preprocessamento\n",
    "# ===================================================\n",
    "\n",
    "def preprocess_full(df: pd.DataFrame, train_len: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Cria√ß√£o de features derivadas, imputa√ß√£o de valores ausentes,\n",
    "    winsoriza√ß√£o suave e normaliza√ß√£o.\n",
    "    \"\"\"\n",
    "    out = df.copy()\n",
    "    \n",
    "    # Normalize text columns\n",
    "    out[\"Sex\"] = out[\"Sex\"].astype(str).str.lower()\n",
    "    out[\"Embarked\"] = out[\"Embarked\"].astype(str).str.upper()\n",
    "\n",
    "    # Name-based features\n",
    "    out[\"Title\"] = out[\"Name\"].apply(extract_title)\n",
    "    title_counts_train = out.iloc[:train_len][\"Title\"].value_counts()\n",
    "    rare_titles = title_counts_train[title_counts_train < 10].index\n",
    "    out[\"Title\"] = out[\"Title\"].where(~out[\"Title\"].isin(rare_titles), \"Rare\")\n",
    "    out[\"LastName\"] = out[\"Name\"].fillna(\"\").apply(lambda s: s.split(\",\")[0].strip() if \",\" in s else \"Unknown\")\n",
    "\n",
    "    # Family / group\n",
    "    out[\"FamilySize\"] = out[\"SibSp\"].fillna(0) + out[\"Parch\"].fillna(0) + 1\n",
    "    out[\"IsAlone\"] = (out[\"FamilySize\"] == 1).astype(int)\n",
    "\n",
    "    # Ticket features\n",
    "    out[\"TicketPrefix\"] = out[\"Ticket\"].apply(clean_ticket_prefix)\n",
    "    ticket_counts = out[\"Ticket\"].fillna(\"NA\").value_counts()\n",
    "    out[\"TicketGroupSize\"] = out[\"Ticket\"].fillna(\"NA\").map(ticket_counts).fillna(1).astype(int)\n",
    "\n",
    "    # Cabin features\n",
    "    out[\"HasCabin\"] = (~out[\"Cabin\"].isna()).astype(int)\n",
    "    out[\"CabinDeck\"] = out[\"Cabin\"].fillna(\"M\").astype(str).str[0].str.upper()\n",
    "    out[\"CabinMulti\"] = out[\"Cabin\"].astype(str).str.contains(r\"\\s\").astype(int)\n",
    "\n",
    "    # Embarked\n",
    "    out[\"Embarked\"] = out[\"Embarked\"].where(out[\"Embarked\"].isin([\"S\",\"C\",\"Q\"]), np.nan)\n",
    "    mode_val = out.iloc[:train_len][\"Embarked\"].mode()\n",
    "    mode_val = mode_val.iloc[0] if not mode_val.empty else \"S\"\n",
    "    out[\"Embarked\"] = out[\"Embarked\"].fillna(mode_val)\n",
    "\n",
    "    # Numeric types\n",
    "    out[\"Pclass\"] = out[\"Pclass\"].astype(int)\n",
    "    out[\"Fare\"] = out[\"Fare\"].astype(float)\n",
    "    out[\"Age\"] = out[\"Age\"].astype(float)\n",
    "\n",
    "    # Imputations\n",
    "    pclass_med = out.iloc[:train_len].groupby(\"Pclass\")[\"Fare\"].median()\n",
    "    out[\"Fare\"] = out.apply(lambda r: pclass_med[r[\"Pclass\"]] if pd.isna(r[\"Fare\"]) else r[\"Fare\"], axis=1)\n",
    "\n",
    "    grp_med = out.iloc[:train_len].groupby([\"Title\",\"Pclass\",\"Sex\"])[\"Age\"].median()\n",
    "    def impute_age(r):\n",
    "        if not pd.isna(r[\"Age\"]): return r[\"Age\"]\n",
    "        key = (r[\"Title\"], r[\"Pclass\"], r[\"Sex\"])\n",
    "        return grp_med.get(key, out.iloc[:train_len][\"Age\"].median())\n",
    "    out[\"Age\"] = out.apply(impute_age, axis=1)\n",
    "\n",
    "    # Derived features\n",
    "    out[\"FarePerPerson\"] = out[\"Fare\"] / out[\"TicketGroupSize\"]\n",
    "    out[\"IsChild\"] = (out[\"Age\"] < 16).astype(int)\n",
    "    out[\"IsMother\"] = ((out[\"Sex\"]==\"female\") & (out[\"Parch\"]>0) & (out[\"Title\"]==\"Mrs\")).astype(int)\n",
    "\n",
    "    # Winsorization suave\n",
    "    out[\"Fare\"] = out[\"Fare\"].clip(0, np.nanpercentile(out[\"Fare\"], 99))\n",
    "    out[\"FarePerPerson\"] = out[\"FarePerPerson\"].clip(0, np.nanpercentile(out[\"FarePerPerson\"], 99))\n",
    "    out[\"Age\"] = out[\"Age\"].clip(0, 80)\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3Ô∏è‚É£ Fun√ß√£o de Preprocessamento\n",
    "\n",
    "O que tem dentro:\n",
    "\n",
    "Normaliza√ß√£o de colunas categ√≥ricas (Sex, Embarked) para evitar inconsist√™ncias.\n",
    "\n",
    "Features derivadas do nome: Title, LastName.\n",
    "\n",
    "Features familiares: FamilySize, IsAlone.\n",
    "\n",
    "Features de ticket: TicketPrefix, TicketGroupSize.\n",
    "\n",
    "Features de cabine: HasCabin, CabinDeck, CabinMulti.\n",
    "\n",
    "Imputa√ß√£o de valores ausentes para Fare e Age.\n",
    "\n",
    "Features derivadas: FarePerPerson, IsChild, IsMother.\n",
    "\n",
    "Winsoriza√ß√£o suave para limitar outliers em Fare, Age e FarePerPerson.\n",
    "\n",
    "Fun√ß√£o:\n",
    "\n",
    "Transformar dados brutos em features num√©ricas e categ√≥ricas limpas, que podem ser usadas diretamente pelo CatBoost.\n",
    "\n",
    "Criar indicadores que capturam padr√µes sociais/familiares importantes para sobreviv√™ncia.\n",
    "\n",
    "Por que escolhi:\n",
    "\n",
    "O CatBoost lida bem com categ√≥ricas, mas features bem pensadas aumentam muito a performance.\n",
    "\n",
    "Winsoriza√ß√£o reduz impacto de outliers extremos, comum em Fare.\n",
    "\n",
    "Imputa√ß√µes baseadas em grupos (Title + Pclass + Sex) respeitam a distribui√ß√£o dos dados e evitam vazamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================\n",
    "# 4Ô∏è‚É£ Fun√ß√£o K-Fold Target Encoding\n",
    "# ===================================================\n",
    "\n",
    "def kfold_target_mean_encode(X_tr: pd.DataFrame, y_tr: pd.Series,\n",
    "                             X_te: pd.DataFrame, col: str,\n",
    "                             n_splits=5, smoothing=20.0, random_state=42) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Target Encoding seguro: calcula m√©dia da vari√°vel target por categoria\n",
    "    usando K-Fold para evitar vazamento de dados.\n",
    "    \"\"\"\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    prior = float(y_tr.mean())\n",
    "\n",
    "    X_tr_col = X_tr[col].reset_index(drop=True)\n",
    "    y_tr_ser = pd.Series(y_tr).reset_index(drop=True)\n",
    "    X_te_col = X_te[col].reset_index(drop=True)\n",
    "\n",
    "    oof = np.zeros(len(X_tr_col), dtype=float)\n",
    "    for tr_idx, va_idx in skf.split(np.zeros(len(y_tr_ser)), y_tr_ser):\n",
    "        df_fold = pd.DataFrame({col: X_tr_col.iloc[tr_idx], \"y\": y_tr_ser.iloc[tr_idx]})\n",
    "        stats = df_fold.groupby(col)[\"y\"].agg([\"mean\",\"count\"])\n",
    "        smooth = (stats[\"mean\"]*stats[\"count\"] + prior*smoothing) / (stats[\"count\"] + smoothing)\n",
    "        oof[va_idx] = X_tr_col.iloc[va_idx].map(smooth).fillna(prior).values\n",
    "\n",
    "    stats_full = pd.DataFrame({col: X_tr_col.values, \"y\": y_tr_ser.values}).groupby(col)[\"y\"].agg([\"mean\",\"count\"])\n",
    "    smooth_full = (stats_full[\"mean\"]*stats_full[\"count\"] + prior*smoothing) / (stats_full[\"count\"] + smoothing)\n",
    "    te = X_te_col.map(smooth_full).fillna(prior).values\n",
    "\n",
    "    return oof, te\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4Ô∏è‚É£ Fun√ß√£o K-Fold Target Encoding\n",
    "\n",
    "O que tem dentro:\n",
    "\n",
    "Codifica√ß√£o de vari√°veis categ√≥ricas de alta cardinalidade (LastName, TicketPrefix) usando a m√©dia da target (Survived) dentro de cada categoria.\n",
    "\n",
    "Uso de Stratified K-Fold para garantir que a m√©dia seja calculada sem vazamento de dados.\n",
    "\n",
    "Suaviza√ß√£o para reduzir overfitting.\n",
    "\n",
    "Fun√ß√£o:\n",
    "\n",
    "Transformar categorias com muitos valores √∫nicos em uma feature num√©rica correlacionada √† target.\n",
    "\n",
    "Evita vazamento de informa√ß√£o entre folds (ou seja, a m√©dia do grupo n√£o ‚Äúvaza‚Äù a informa√ß√£o do fold de valida√ß√£o).\n",
    "\n",
    "Por que escolhi:\n",
    "\n",
    "Vari√°veis como LastName ou TicketPrefix s√£o muito espec√≠ficas e n√£o podem ser one-hot encoded.\n",
    "\n",
    "K-Fold target encoding com smoothing √© a t√©cnica segura mais eficiente para isso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================\n",
    "# 5Ô∏è‚É£ Carregamento dos Dados e Preprocessamento\n",
    "# ===================================================\n",
    "\n",
    "seed_everything(RANDOM_STATE)\n",
    "INPUT_DIR = detect_input_dir()\n",
    "\n",
    "train = pd.read_csv(os.path.join(INPUT_DIR, \"train.csv\"))\n",
    "test  = pd.read_csv(os.path.join(INPUT_DIR, \"test.csv\"))\n",
    "\n",
    "y = train[\"Survived\"].astype(int)\n",
    "train_nolabel = train.drop(columns=[\"Survived\"])\n",
    "full = pd.concat([train_nolabel, test], axis=0, ignore_index=True)\n",
    "\n",
    "full = preprocess_full(full, train_len=len(train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5Ô∏è‚É£ Carregamento dos Dados e Preprocessamento\n",
    "\n",
    "O que tem dentro:\n",
    "\n",
    "Leitura de train.csv e test.csv.\n",
    "\n",
    "Separa√ß√£o de y (target) e features.\n",
    "\n",
    "Concatenar train + test para pr√©-processar juntos (evita inconsist√™ncia de categorias).\n",
    "\n",
    "Chamada da fun√ß√£o preprocess_full.\n",
    "\n",
    "Fun√ß√£o:\n",
    "\n",
    "Preparar dataset completo para feature engineering, mantendo separa√ß√£o correta entre treino e teste.\n",
    "\n",
    "Por que escolhi:\n",
    "\n",
    "Processar juntos evita que categorias novas no teste n√£o sejam tratadas.\n",
    "\n",
    "Mant√©m consist√™ncia para target encoding e outras features derivadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================\n",
    "# 6Ô∏è‚É£ Target Encoding de Vari√°veis Categ√≥ricas de Alta Cardinalidade\n",
    "# ===================================================\n",
    "\n",
    "base_cat = [\"Sex\",\"Embarked\",\"Title\",\"CabinDeck\",\"TicketPrefix\"]\n",
    "base_num = [\"Pclass\",\"Age\",\"SibSp\",\"Parch\",\"Fare\",\"FamilySize\",\"IsAlone\",\n",
    "            \"IsChild\",\"IsMother\",\"HasCabin\",\"CabinMulti\",\"TicketGroupSize\",\"FarePerPerson\"]\n",
    "\n",
    "te_cols = [\"LastName\",\"TicketPrefix\",\"CabinDeck\",\"Title\"]\n",
    "n_train = len(train)\n",
    "train_idx = np.arange(n_train)\n",
    "test_idx  = np.arange(n_train, len(full))\n",
    "\n",
    "X_all = full.copy()\n",
    "te_train_parts, te_test_parts = {}, {}\n",
    "for c in te_cols:\n",
    "    oof_c, test_c = kfold_target_mean_encode(\n",
    "        X_all.loc[train_idx,[c]], y, X_all.loc[test_idx,[c]],\n",
    "        col=c, n_splits=N_SPLITS, smoothing=TE_SMOOTHING, random_state=RANDOM_STATE\n",
    "    )\n",
    "    te_train_parts[c+\"_TE\"] = oof_c\n",
    "    te_test_parts[c+\"_TE\"] = test_c\n",
    "\n",
    "for newc, arr in te_train_parts.items(): X_all.loc[train_idx, newc] = arr\n",
    "for newc, arr in te_test_parts.items():  X_all.loc[test_idx, newc] = arr\n",
    "\n",
    "use_cols = base_cat + base_num + [c+\"_TE\" for c in te_cols]\n",
    "X_train = X_all.loc[train_idx, use_cols].reset_index(drop=True)\n",
    "X_test  = X_all.loc[test_idx,  use_cols].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6Ô∏è‚É£ Target Encoding de Vari√°veis de Alta Cardinalidade\n",
    "\n",
    "O que tem dentro:\n",
    "\n",
    "Lista de vari√°veis a encodar (te_cols).\n",
    "\n",
    "Loop que aplica kfold_target_mean_encode em cada coluna.\n",
    "\n",
    "Adiciona colunas codificadas (_TE) ao dataframe.\n",
    "\n",
    "Fun√ß√£o:\n",
    "\n",
    "Transformar vari√°veis categ√≥ricas complexas em features num√©ricas seguras.\n",
    "\n",
    "Preparar dataset pronto para o CatBoost.\n",
    "\n",
    "Por que escolhi:\n",
    "\n",
    "Evita overfitting e vazamento, enquanto permite aproveitar informa√ß√µes valiosas de categorias raras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================\n",
    "# 7Ô∏è‚É£ Treinamento CatBoost com CV\n",
    "# ===================================================\n",
    "\n",
    "cat_idx = [X_train.columns.get_loc(c) for c in base_cat]  # Indices das colunas categ√≥ricas\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "oof = np.zeros(len(X_train))\n",
    "test_pred_folds = np.zeros((N_SPLITS, len(X_test)))\n",
    "fold_acc = []\n",
    "\n",
    "for fold, (tr, va) in enumerate(skf.split(X_train, y), 1):\n",
    "    X_tr, X_va = X_train.iloc[tr], X_train.iloc[va]\n",
    "    y_tr, y_va = y.iloc[tr], y.iloc[va]\n",
    "\n",
    "    est = CatBoostClassifier(\n",
    "        depth=6, learning_rate=0.05, iterations=3000, l2_leaf_reg=3.0,\n",
    "        loss_function=\"Logloss\", eval_metric=\"Accuracy\",\n",
    "        random_seed=RANDOM_STATE+fold, od_type=\"Iter\", od_wait=EARLY_STOPPING_ROUNDS, verbose=False\n",
    "    )\n",
    "    tr_pool = Pool(X_tr, y_tr, cat_features=cat_idx)\n",
    "    va_pool = Pool(X_va, y_va, cat_features=cat_idx)\n",
    "    te_pool = Pool(X_test, cat_features=cat_idx)\n",
    "\n",
    "    est.fit(tr_pool, eval_set=va_pool, use_best_model=True)\n",
    "    va_p = est.predict_proba(va_pool)[:,1]\n",
    "    te_p = est.predict_proba(te_pool)[:,1]\n",
    "\n",
    "    oof[va] = va_p\n",
    "    test_pred_folds[fold-1,:] = te_p\n",
    "    fold_acc.append(accuracy_score(y_va, (va_p>=0.5).astype(int)))\n",
    "\n",
    "print(\"CatBoost CV Acc per fold:\", [f\"{a:.4f}\" for a in fold_acc], \"| Mean:\", f\"{np.mean(fold_acc):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7Ô∏è‚É£ Treinamento CatBoost com Cross-Validation\n",
    "\n",
    "O que tem dentro:\n",
    "\n",
    "Cria√ß√£o de folds estratificados.\n",
    "\n",
    "Treinamento do CatBoost em cada fold.\n",
    "\n",
    "Armazenamento das previs√µes OOF (out-of-fold) e previs√£o para teste.\n",
    "\n",
    "C√°lculo de acur√°cia em cada fold.\n",
    "\n",
    "Fun√ß√£o:\n",
    "\n",
    "Treinar modelo robusto com valida√ß√£o cruzada.\n",
    "\n",
    "Obter estimativas OOF para tuning de threshold e an√°lise de performance.\n",
    "\n",
    "Por que escolhi:\n",
    "\n",
    "CatBoost √© r√°pido e eficiente para dados mistos.\n",
    "\n",
    "CV estratificado garante avalia√ß√£o justa e reduz vari√¢ncia na valida√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================\n",
    "# 8Ô∏è‚É£ Threshold tuning OOF\n",
    "# ===================================================\n",
    "\n",
    "ths = np.linspace(0.3,0.7,401)\n",
    "best_t, best_acc = max(((t, accuracy_score(y,(oof>=t).astype(int))) for t in ths), key=lambda x:x[1])\n",
    "print(f\"OOF Accuracy = {best_acc:.4f} at threshold = {best_t:.3f}\")\n",
    "\n",
    "test_prob = test_pred_folds.mean(axis=0)\n",
    "pred = (test_prob >= best_t).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8Ô∏è‚É£ Threshold tuning OOF\n",
    "\n",
    "O que tem dentro:\n",
    "\n",
    "Varredura de thresholds entre 0.3 e 0.7.\n",
    "\n",
    "Sele√ß√£o do threshold que maximiza acur√°cia OOF.\n",
    "\n",
    "Aplica√ß√£o do threshold ao teste.\n",
    "\n",
    "Fun√ß√£o:\n",
    "\n",
    "Ajustar ponto de corte para transformar probabilidades em classes (0/1) de forma otimizada.\n",
    "\n",
    "Por que escolhi:\n",
    "\n",
    "O threshold default (0.5) pode n√£o ser ideal devido a desbalanceamento.\n",
    "\n",
    "Melhora acur√°cia sem mexer no modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================\n",
    "# 9Ô∏è‚É£ Pseudo-labeling opcional (safe)\n",
    "# ===================================================\n",
    "\n",
    "if PSEUDO_LABEL:\n",
    "    high_pos = np.where(test_prob >= PL_POS_THR)[0]\n",
    "    high_neg = np.where(test_prob <= PL_NEG_THR)[0]\n",
    "    sel = np.concatenate([high_pos, high_neg])\n",
    "\n",
    "    if sel.size > 0:\n",
    "        X_aug = pd.concat([X_train, X_test.iloc[sel]], axis=0, ignore_index=True)\n",
    "        y_aug = pd.concat([y.reset_index(drop=True),\n",
    "                           pd.Series((test_prob[sel] >= PL_POS_THR).astype(int))],\n",
    "                          axis=0).reset_index(drop=True)\n",
    "\n",
    "        oof2 = np.zeros(len(X_train))\n",
    "        test_pred_folds2 = np.zeros((N_SPLITS,len(X_test)))\n",
    "        fold_acc2 = []\n",
    "\n",
    "        for fold, (tr, va) in enumerate(skf.split(X_train,y),1):\n",
    "            tr_idx_aug = np.concatenate([tr, n_train+np.arange(len(sel))])\n",
    "            X_tr2, y_tr2 = X_aug.iloc[tr_idx_aug], y_aug.iloc[tr_idx_aug]\n",
    "            X_va2, y_va2 = X_train.iloc[va], y.iloc[va]\n",
    "\n",
    "            est2 = CatBoostClassifier(\n",
    "                depth=6, learning_rate=0.05, iterations=3000, l2_leaf_reg=3.0,\n",
    "                loss_function=\"Logloss\", eval_metric=\"Accuracy\",\n",
    "                random_seed=RANDOM_STATE+123+fold, od_type=\"Iter\", od_wait=EARLY_STOPPING_ROUNDS, verbose=False\n",
    "            )\n",
    "            tr_pool2 = Pool(X_tr2, y_tr2, cat_features=cat_idx)\n",
    "            va_pool2 = Pool(X_va2, y_va2, cat_features=cat_idx)\n",
    "            te_pool2 = Pool(X_test, cat_features=cat_idx)\n",
    "\n",
    "            est2.fit(tr_pool2, eval_set=va_pool2, use_best_model=True)\n",
    "            va_p2 = est2.predict_proba(va_pool2)[:,1]\n",
    "            te_p2 = est2.predict_proba(te_pool2)[:,1]\n",
    "\n",
    "            oof2[va] = va_p2\n",
    "            test_pred_folds2[fold-1,:] = te_p2\n",
    "            fold_acc2.append(accuracy_score(y_va2, (va_p2>=0.5).astype(int)))\n",
    "\n",
    "        print(\"PL CatBoost CV Acc per fold:\", [f\"{a:.4f}\" for a in fold_acc2], \"| Mean:\", f\"{np.mean(fold_acc2):.4f}\")\n",
    "        ths2 = np.linspace(0.3,0.7,401)\n",
    "        best_t2, best_acc2 = max(((t, accuracy_score(y,(oof2>=t).astype(int))) for t in ths2), key=lambda x:x[1])\n",
    "        print(f\"[PL] OOF Accuracy = {best_acc2:.4f} at threshold = {best_t2:.3f}\")\n",
    "\n",
    "        test_prob = test_pred_folds2.mean(axis=0)\n",
    "        pred = (test_prob >= best_t2).astype(int)\n",
    "    else:\n",
    "        print(\"No high-confidence test samples for pseudo-labeling; skipping.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9Ô∏è‚É£ Pseudo-labeling opcional\n",
    "\n",
    "O que tem dentro:\n",
    "\n",
    "Sele√ß√£o de amostras de teste com alta confian√ßa (>=0.98 ou <=0.02).\n",
    "\n",
    "Adi√ß√£o dessas amostras ao treino com labels previstos.\n",
    "\n",
    "Retraining do CatBoost sem recalcular target encoding.\n",
    "\n",
    "Fun√ß√£o:\n",
    "\n",
    "Aumentar o dataset de treino com exemplos confi√°veis do teste, para potencial melhoria de performance.\n",
    "\n",
    "Por que escolhi:\n",
    "\n",
    "T√©cnica leve e segura, s√≥ uma rodada, evita overfitting.\n",
    "\n",
    "√ötil em competi√ß√µes com leaderboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================\n",
    "# üîü Submission\n",
    "# ===================================================\n",
    "\n",
    "sub = pd.DataFrame({\"PassengerId\": test[\"PassengerId\"].values, \"Survived\": pred})\n",
    "sub.to_csv(\"submission.csv\", index=False)\n",
    "print(\"Saved: submission.csv\", sub.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîü Submission\n",
    "\n",
    "O que tem dentro:\n",
    "\n",
    "Cria√ß√£o do dataframe de submiss√£o com PassengerId e Survived.\n",
    "\n",
    "Salvamento em CSV.\n",
    "\n",
    "Fun√ß√£o:\n",
    "\n",
    "Gerar arquivo pronto para submiss√£o no Kaggle.\n",
    "\n",
    "Por que escolhi:\n",
    "\n",
    "Padr√£o obrigat√≥rio da competi√ß√£o Titanic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explica√ß√£o geral:\n",
    "Este notebook implementa um pipeline robusto para o desafio do Titanic, com foco em evitar vazamento de dados (leakage) e maximizar acur√°cia de valida√ß√£o.\n",
    "\n",
    "Preprocessamento: Cria√ß√£o de features relevantes a partir de nomes, tickets, cabine e rela√ß√µes familiares.\n",
    "\n",
    "Target Encoding: Codifica√ß√£o de vari√°veis categ√≥ricas de alta cardinalidade de forma segura via K-Fold (sem vazamento).\n",
    "\n",
    "Treinamento: CatBoost com valida√ß√£o cruzada e early stopping.\n",
    "\n",
    "Threshold tuning: Ajuste do threshold de probabilidade para melhorar a acur√°cia OOF.\n",
    "\n",
    "Pseudo-labeling (opcional): Inclus√£o de amostras de teste de alta confian√ßa para potencial ganho de performance.\n",
    "\n",
    "Submission: Gera√ß√£o do arquivo submission.csv pronto para Kaggle."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
